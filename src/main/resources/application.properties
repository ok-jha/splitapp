spring.application.name=splitapp
# src/main/resources/application.properties

# --- Server Configuration ---
# Port the Spring Boot application will run on
server.port=8081

# --- Database Configuration (Connecting to LOCAL PostgreSQL) ---
# URL for your local PostgreSQL instance and the specific database
spring.datasource.url=jdbc:postgresql://localhost:5432/splitapp_db
# Username you created for the application
spring.datasource.username=splitapp_user
# Password for the application user - REPLACE THIS!
spring.datasource.password=postgres
# Standard JDBC driver class for PostgreSQL
spring.datasource.driver-class-name=org.postgresql.Driver

# --- JPA / Hibernate Configuration ---
# Database platform dialect
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
# Show SQL queries generated by Hibernate in the logs (useful for debugging)
spring.jpa.show-sql=true
# Format the logged SQL queries to be more readable
spring.jpa.properties.hibernate.format_sql=true
# IMPORTANT: Database Schema Management Strategy
# 'update': Hibernate tries to update the schema based on your @Entity classes. Good for EARLY dev.
# 'validate': Checks if the schema matches entities, throws error if not. Safer.
# 'create': Drops and recreates schema on startup (LOSES DATA).
# 'create-drop': Creates on startup, drops on shutdown (LOSES DATA).
# 'none': Does nothing. Recommended for PROD with tools like Flyway/Liquibase.
# We use 'update' for now, but plan to change later.
spring.jpa.hibernate.ddl-auto=update

# --- Kafka Configuration (Connecting to DOCKERIZED Kafka) ---
# Address of the Kafka broker(s). Points to the EXTERNAL listener (port 29092)
# defined in docker-compose.yml
spring.kafka.bootstrap-servers=localhost:29092
# Default consumer group ID for Kafka consumers created by this application
spring.kafka.consumer.group-id=splitapp-consumer-group
# Optional: Add producer/consumer specific properties if needed later
# spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
# spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
# spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
# spring.kafka.consumer.properties.spring.json.trusted.packages=* # Be careful with this in production

# --- Actuator Configuration (for monitoring/health checks) ---
# Expose the 'health' endpoint over the web
management.endpoints.web.exposure.include=health
# Show details in the health endpoint (e.g., DB connection status)
# Set to 'always' for easy viewing in dev, 'when_authorized' or 'never' for prod.
management.endpoint.health.show-details=always

# --- Optional: Logging Configuration ---
# logging.level.org.springframework=INFO
# logging.level.org.hibernate.SQL=DEBUG # More detailed SQL logging if needed
# logging.level.com.yourgithubusername.splitapp=DEBUG # Set your base package to DEBUG